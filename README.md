How this program works currently as of 01/31/2023

moto_scrape.py reads a dictionary of states with corresponding lists of cities as stipulated in moto_scrape_data.py. It will then create a csv for each state containing the data from every craigslist motorcycle ad. This takes a long time initially and will probably get flagged by craigslist so manipulating the moto_scrape_data.py file to only do a few cities at a time would be wise. The initial scrape can take a while, but subsequent scrapes, so long as the csv files can be read back into the program, will only need to update with ads created since the last scrape.

How this program works is that for each list of cities for each state, the search results are combed through page by page to create a long list of all the ad urls. That list can contain duplicates (due to a small cities showing ads for surrounding areas) so therefore a deduplication is run on this list. If there is existing data to read from (a csv read into the program as a pandas dataframe, while saving an old version of the csv as a precaution), the program will compare the list of ad urls just scraped with the previously scraped ads and remove all matches, leaving only the new ads to scrape since last time. If there is no existing data to read from this deduplication process is skipped. 

The program then systematically opens each ad and scrapes all of the ad data and adds it to a new row in the dataframe. Once this has been done for each cities ads in the state, then the resulting dataframe is deduped one last time (although this step may no longer be necessary due to teh addition of the previous dedupliation step) before being written back to a csv file. The process is then repeated for the next state in the dictionary.